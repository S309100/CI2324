{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MAGIC = [2, 7, 6, 9, 5, 1, 4, 3, 8]\n",
    "class State:\n",
    "    def __init__(self, x, o):\n",
    "        self.x = frozenset(x)\n",
    "        self.o = frozenset(o)\n",
    "def print_board(pos):\n",
    "    \"\"\"Nicely prints the board\"\"\"\n",
    "    for r in range(3):\n",
    "        for c in range(3):\n",
    "            i = r * 3 + c\n",
    "            if MAGIC[i] in pos.x:\n",
    "                print('X', end='')\n",
    "            elif MAGIC[i] in pos.o:\n",
    "                print('O', end='')\n",
    "            else:\n",
    "                print('.', end='')\n",
    "        print()\n",
    "    print()\n",
    "\n",
    "def win(elements):\n",
    "    \"\"\"Checks if elements form a winning combination\"\"\"\n",
    "    elements = [e for e in elements if e is not None]\n",
    "    return any(sum(c) == 15 for c in combinations(elements, 3))\n",
    "\n",
    "def state_value(pos: State):\n",
    "\n",
    "    if win(pos.x):\n",
    "        return 1\n",
    "    elif win(pos.o):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def random_game():\n",
    "    trajectory = list()\n",
    "    state = State(frozenset(), frozenset())\n",
    "    available = set(range(1, 9 + 1))\n",
    "    while available:\n",
    "        x = choice(list(available))\n",
    "        state = State(state.x.union({x}), state.o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x)\n",
    "        if win(state.x) or not available:\n",
    "            break\n",
    "\n",
    "        o = choice(list(available))\n",
    "        state = State(state.x, state.o.union({o}))\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "        if win(state.o):\n",
    "            break\n",
    "    return trajectory\n",
    "\n",
    "def random_agent(state):\n",
    "    \"\"\"\n",
    "    Random agent that selects a valid move randomly.\n",
    "    \"\"\"\n",
    "    valid_moves = list(set(range(1, 9 + 1)) - (state.x.union(state.o)))\n",
    "    if not valid_moves:\n",
    "        return None\n",
    "    return choice(valid_moves)\n",
    "class QLearningAgent:\n",
    "    def __init__(self, epsilon=0.1, alpha=0.1, gamma=0.9):\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.q_values = defaultdict(float)\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.q_values[(state.x,state.o, action)]\n",
    "\n",
    "    def choose_action(self, state, valid_actions):\n",
    "        if not valid_actions:\n",
    "            return None  # No valid actions available\n",
    "        elif np.random.rand() < self.epsilon:\n",
    "            return choice(valid_actions)\n",
    "        else:\n",
    "            q_values = [self.get_q_value(state, a) for a in valid_actions]\n",
    "            return valid_actions[np.argmax(q_values)]\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        current_q = self.get_q_value(state, action)\n",
    "        max_next_q = max([self.get_q_value(next_state, a) for a in range(1, 9 + 1)])\n",
    "        new_q = (1 - self.alpha) * current_q + self.alpha * (reward + self.gamma * max_next_q)\n",
    "        self.q_values[(state.x,state.o, action)] = new_q\n",
    "\n",
    "    def play_against_random_agent(self):\n",
    "        state = State(frozenset(), frozenset())\n",
    "        while True:\n",
    "            # Q-learning agent's turn\n",
    "            valid_actions_q = list(set(range(1, 9 + 1)) - (state.x.union(state.o)))\n",
    "            action_q = self.choose_action(state, valid_actions=valid_actions_q)\n",
    "            if action_q is None:\n",
    "                return \"It's a tie! (No valid actions remaining)\"\n",
    "            state= State(state.x.union({action_q}), state.o)\n",
    "            if win(state.x):\n",
    "                return \"QLearningAgent wins!\"\n",
    "            elif not valid_actions_q:\n",
    "                return \"It's a tie!\"\n",
    "\n",
    "            # Random agent's turn\n",
    "            valid_actions_random = list(set(range(1, 9 + 1)) - (state.x.union(state.o)))\n",
    "            action_random = random_agent(state)\n",
    "            state = State(state.x, state.o.union({action_random}))\n",
    "            if win(state.o):\n",
    "                return \"Random Agent wins!\"\n",
    "            elif not valid_actions_random:\n",
    "                return \"It's a tie!\"\n",
    "# Training with Q-learning\n",
    "value_dictionary = defaultdict(float)\n",
    "hit_state = defaultdict(int)\n",
    "agent = QLearningAgent(epsilon=0.001, alpha=0.05, gamma=0.09)\n",
    "q_agent_wins=0\n",
    "for steps in tqdm(range(10000)):\n",
    "    trajectory = random_game()\n",
    "    for i in range(len(trajectory) - 1):\n",
    "        state = trajectory[i]\n",
    "        next_state = trajectory[i + 1]\n",
    "        action = agent.choose_action(state, valid_actions = list(set(range(1, 9 + 1))-(state.x.union(state.o))))  # Choose a random action for simplicity\n",
    "        final_reward = state_value(next_state)\n",
    "        agent.update_q_value(state, action, final_reward, next_state)\n",
    "\n",
    "# Display the top 10 states based on their Q-values\n",
    "top_states = sorted(agent.q_values.items(), key=lambda e: e[1], reverse=True)[:10]\n",
    "for state_action, q_value in top_states:\n",
    "    state_x, state_o, action = state_action\n",
    "    print(f\"State X: {state_x}, State O: {state_o}, Q-value: {q_value}\")\n",
    "result = agent.play_against_random_agent()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
